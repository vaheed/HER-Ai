# LLM Provider (ollama, openai, groq, or openrouter)
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.2:3b
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_HOST=http://ollama:11434
# Optional override for compose pre-pull job
OLLAMA_EMBED_MODEL=nomic-embed-text

# Optional cloud providers (required only when selected)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
GROQ_API_KEY=gsk_...
GROQ_MODEL=llama-3.3-70b-versatile
GROQ_API_BASE=https://api.groq.com/openai/v1
OPENROUTER_API_KEY=sk-or-...
OPENROUTER_MODEL=meta-llama/llama-3.3-70b-instruct
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# Memory / Embeddings
MEMORY_VECTOR_PROVIDER=pgvector
MEMORY_COLLECTION_NAME=memories
# When false, bot keeps replying even if long-term memory backend is temporarily unavailable
MEMORY_STRICT_MODE=false
EMBEDDER_PROVIDER=ollama
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIMENSIONS=768

# Database
POSTGRES_USER=her
POSTGRES_PASSWORD=changeme123
POSTGRES_DB=her_memory
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=changeme456

# App
LOG_LEVEL=INFO
ENVIRONMENT=development

# Optional startup self-checks (disabled by default to avoid provider rate-limit crashes)
STARTUP_WARMUP_ENABLED=false

# Telegram
TELEGRAM_ENABLED=true
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
ADMIN_USER_ID=your_telegram_user_id
# Retry delay (seconds) when Telegram API is temporarily unreachable
TELEGRAM_STARTUP_RETRY_DELAY_SECONDS=10
