version: "3.9"

services:
  her-bot:
    image: ghcr.io/vaheed/her-ai/her-bot:latest
    container_name: her-bot
    env_file:
      - .env
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
      ollama-init:
        condition: service_completed_successfully
    networks:
      - her-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 8000)); s.close()"]
      interval: 30s
      timeout: 5s
      retries: 3

  postgres:
    image: pgvector/pgvector:pg16
    container_name: her-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-her}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme123}
      POSTGRES_DB: ${POSTGRES_DB:-her_memory}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - her-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-her} -d ${POSTGRES_DB:-her_memory}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: her-redis
    command: ["redis-server", "--appendonly", "yes", "--requirepass", "${REDIS_PASSWORD:-changeme456}"]
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - her-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-changeme456}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  ollama:
    image: ollama/ollama:0.5.7
    container_name: her-ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    networks:
      - her-network
    restart: unless-stopped
    mem_limit: 2g
    cpus: 1.50
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -fsS http://localhost:11434/api/tags >/dev/null"]
      interval: 30s
      timeout: 5s
      retries: 10

  ollama-init:
    image: ollama/ollama:0.5.7
    container_name: her-ollama-init
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:3b}
      OLLAMA_EMBED_MODEL: ${OLLAMA_EMBED_MODEL:-nomic-embed-text}
    entrypoint: ["/bin/bash", "-lc"]
    command: >
      'set -e;
      echo "Waiting for Ollama at $OLLAMA_BASE_URL";
      until curl -fsS "$OLLAMA_BASE_URL/api/tags" >/dev/null; do sleep 2; done;
      echo "Pulling embedding model: $OLLAMA_EMBED_MODEL";
      ollama pull "$OLLAMA_EMBED_MODEL";
      echo "Pulling chat model: $OLLAMA_MODEL";
      ollama pull "$OLLAMA_MODEL";
      echo "Ollama models ready."'
    networks:
      - her-network
    restart: "no"

  sandbox:
    image: ghcr.io/vaheed/her-ai/her-sandbox:latest
    container_name: her-sandbox
    networks:
      - her-network
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
    volumes:
      - sandbox_workspace:/workspace
    healthcheck:
      test: ["CMD", "bash", "-lc", "test -d /workspace"]
      interval: 30s
      timeout: 5s
      retries: 3

  dashboard:
    image: ghcr.io/vaheed/her-ai/her-dashboard:latest
    container_name: her-dashboard
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
      ollama-init:
        condition: service_completed_successfully
    env_file:
      - .env
    ports:
      - "8501:8501"
    networks:
      - her-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost', 8501)); s.close()"]
      interval: 30s
      timeout: 5s
      retries: 3

networks:
  her-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  sandbox_workspace:
  ollama_data:
