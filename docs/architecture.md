# HER System Architecture

> Comprehensive technical architecture documentation for the HER AI Assistant system

## ğŸ“ System Overview

HER is a containerized, multi-agent AI assistant system built using modern cloud-native principles. The architecture prioritizes modularity, scalability, and maintainability while ensuring data persistence and emotional intelligence.

### Core Design Principles

1. **Container-First**: Every component runs in Docker containers
2. **Stateful Intelligence**: Persistent memory across sessions
3. **Agent-Based**: Specialized agents for different responsibilities
4. **API-Driven**: LLM providers accessed via standard APIs (OpenAI, Groq)
5. **Security-Focused**: Sandboxed execution, encrypted storage
6. **Observable**: Comprehensive logging and monitoring

---

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          User Interface Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Telegram Bot      â”‚              â”‚  Admin Dashboard        â”‚    â”‚
â”‚  â”‚  (python-telegram) â”‚              â”‚  (Streamlit)            â”‚    â”‚
â”‚  â”‚  - Admin Mode      â”‚              â”‚  - Real-time Monitor    â”‚    â”‚
â”‚  â”‚  - Public Mode     â”‚              â”‚  - Personality Tuner    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Application Layer (HER Core)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    CrewAI Agent Orchestrator                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚Conversation  â”‚  â”‚  Reflection  â”‚  â”‚   Personality    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚   Agent      â”‚  â”‚    Agent     â”‚  â”‚  Evolution Agent â”‚   â”‚  â”‚
â”‚  â”‚  â”‚              â”‚  â”‚              â”‚  â”‚                  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚ - Chat flow  â”‚  â”‚ - Analysis   â”‚  â”‚ - Trait adjust   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚ - Context    â”‚  â”‚ - Memory     â”‚  â”‚ - Safety bounds  â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                               â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚  â”‚
â”‚  â”‚  â”‚  Tool Agent  â”‚                                            â”‚  â”‚
â”‚  â”‚  â”‚              â”‚                                            â”‚  â”‚
â”‚  â”‚  â”‚ - Web Search â”‚                                            â”‚  â”‚
â”‚  â”‚  â”‚ - Code Exec  â”‚                                            â”‚  â”‚
â”‚  â”‚  â”‚ - File Ops   â”‚                                            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Memory Layer (Mem0)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Short-Term Memory     â”‚    â”‚    Long-Term Memory          â”‚   â”‚
â”‚  â”‚   (Redis)               â”‚    â”‚    (PostgreSQL + pgvector)   â”‚   â”‚
â”‚  â”‚                         â”‚    â”‚                              â”‚   â”‚
â”‚  â”‚ - Conversation context  â”‚    â”‚ - User facts/preferences     â”‚   â”‚
â”‚  â”‚ - Recent messages       â”‚    â”‚ - Emotional patterns         â”‚   â”‚
â”‚  â”‚ - Active sessions       â”‚    â”‚ - Significant events         â”‚   â”‚
â”‚  â”‚ - TTL: 24 hours         â”‚    â”‚ - Semantic embeddings        â”‚   â”‚
â”‚  â”‚                         â”‚    â”‚ - Personality versions       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        External Services Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ LLM Provider â”‚  â”‚ Web Search   â”‚  â”‚  Sandbox Execution       â”‚  â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚  (Ubuntu Container)      â”‚  â”‚
â”‚  â”‚ - OpenAI API â”‚  â”‚ - DuckDuckGo â”‚  â”‚                          â”‚  â”‚
â”‚  â”‚ - Groq API   â”‚  â”‚ - Serper API â”‚  â”‚ - Python runtime         â”‚  â”‚
â”‚  â”‚              â”‚  â”‚ - SearXNG    â”‚  â”‚ - Node.js runtime        â”‚  â”‚
â”‚  â”‚ GPT-4, Llama â”‚  â”‚              â”‚  â”‚ - Restricted user        â”‚  â”‚
â”‚  â”‚ Mixtral, etc â”‚  â”‚              â”‚  â”‚ - Network isolated       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Container Architecture

### Docker Compose Services

```yaml
services:
  # Main application container
  her-bot:
    build: ./her-core
    container_name: her-bot
    depends_on:
      - postgres
      - redis
      - sandbox
    environment:
      - TELEGRAM_BOT_TOKEN
      - OPENAI_API_KEY
      - GROQ_API_KEY
      - POSTGRES_URL
      - REDIS_URL
    networks:
      - her-network
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
    restart: unless-stopped
    
  # PostgreSQL with pgvector
  postgres:
    image: pgvector/pgvector:pg16
    container_name: her-postgres
    environment:
      - POSTGRES_USER
      - POSTGRES_PASSWORD
      - POSTGRES_DB=her_memory
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
      - her-network
    restart: unless-stopped
    
  # Redis for short-term memory
  redis:
    image: redis:7-alpine
    container_name: her-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    networks:
      - her-network
    restart: unless-stopped
    
  # Ubuntu sandbox for code execution
  sandbox:
    build: ./sandbox
    container_name: her-sandbox
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100M
      - /workspace:size=500M
    networks:
      - her-network
    restart: unless-stopped
    
  # Streamlit dashboard
  dashboard:
    build: ./dashboard
    container_name: her-dashboard
    depends_on:
      - postgres
      - redis
    ports:
      - "8501:8501"
    environment:
      - POSTGRES_URL
      - REDIS_URL
    networks:
      - her-network
    restart: unless-stopped

networks:
  her-network:
    driver: bridge

volumes:
  postgres-data:
  redis-data:
```

### Container Specifications

| Container | Base Image | CPU Limit | Memory Limit | Disk | Purpose |
|-----------|------------|-----------|--------------|------|---------|
| her-bot | python:3.11-slim | 2 cores | 1GB | 500MB | Main application |
| postgres | pgvector/pgvector:pg16 | 1 core | 512MB | 10GB | Long-term memory |
| redis | redis:7-alpine | 0.5 core | 256MB | 1GB | Short-term cache |
| sandbox | ubuntu:22.04 | 1 core | 512MB | 1GB | Code execution |
| dashboard | python:3.11-slim | 0.5 core | 512MB | 200MB | Admin UI |

---

## ğŸ§  Agent System Architecture (CrewAI)

### Agent Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Agent Orchestrator                        â”‚
â”‚                    (CrewAI Framework)                        â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                                                     â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚                 â”‚                 â”‚                â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚Conversationâ”‚   â”‚  Reflection  â”‚  â”‚Personality â”‚  â”‚    Tool    â”‚
â”‚   Agent    â”‚   â”‚    Agent     â”‚  â”‚ Evolution  â”‚  â”‚   Agent    â”‚
â”‚            â”‚   â”‚              â”‚  â”‚   Agent    â”‚  â”‚            â”‚
â”‚Primary LLM â”‚   â”‚Analysis LLM  â”‚  â”‚Update LLM  â”‚  â”‚Executor    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Interaction Flow

```
User Message
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conversation Agent  â”‚
â”‚                     â”‚
â”‚ 1. Receive message  â”‚
â”‚ 2. Retrieve context â”‚â—„â”€â”€â”€â”€â”€â”
â”‚    from Redis       â”‚      â”‚
â”‚ 3. Search memories  â”‚â”€â”€â”   â”‚
â”‚    (semantic)       â”‚  â”‚   â”‚
â”‚ 4. Generate responseâ”‚  â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
           â”‚             â”‚   â”‚
           â–¼             â–¼   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Tool Agent   â”‚  â”‚ Memory (DB) â”‚
    â”‚              â”‚  â”‚             â”‚
    â”‚ - Web search â”‚  â”‚ Semantic    â”‚
    â”‚ - Code exec  â”‚  â”‚ search on   â”‚
    â”‚ - File ops   â”‚  â”‚ embeddings  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    Response to User
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Reflection Agent   â”‚
    â”‚                    â”‚
    â”‚ 1. Analyze convo   â”‚
    â”‚ 2. Score importanceâ”‚
    â”‚ 3. Extract memoriesâ”‚
    â”‚ 4. Store to DB     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 5. Suggest updates â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
               â”‚                        â”‚
               â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Personality Evolutionâ”‚    â”‚  Long-term  â”‚
    â”‚       Agent          â”‚    â”‚   Memory    â”‚
    â”‚                      â”‚    â”‚  (Postgres) â”‚
    â”‚ 1. Review patterns   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ 2. Adjust traits     â”‚
    â”‚ 3. Enforce bounds    â”‚
    â”‚ 4. Version & save    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Configuration

```python
# config/agents.yaml

conversation_agent:
  role: "Empathetic Conversationalist"
  goal: "Engage users with warmth while maintaining context"
  backstory: >
    You are HER, an emotionally intelligent AI companion. You remember 
    past conversations, adapt to user preferences, and provide thoughtful,
    contextual responses. You're curious, warm, and genuine.
  llm:
    provider: "openai"  # or "groq"
    model: "gpt-4-turbo-preview"
    temperature: 0.7
    max_tokens: 500
  tools:
    - memory_search
    - web_search_tool
    - current_time
  max_iterations: 3
  
reflection_agent:
  role: "Memory Curator"
  goal: "Identify and preserve meaningful moments"
  backstory: >
    You analyze conversations to determine what's worth remembering.
    You extract facts, preferences, emotions, and significant events.
    You're analytical but understand human nuance.
  llm:
    provider: "openai"
    model: "gpt-4-turbo-preview"
    temperature: 0.3
    max_tokens: 1000
  tools:
    - importance_scorer
    - memory_extractor
    - emotion_detector
  schedule: "*/5 * * * *"  # Every 5 minutes
  importance_threshold: 0.7
  
personality_evolution_agent:
  role: "Character Developer"
  goal: "Evolve personality based on interactions"
  backstory: >
    You observe interaction patterns and adjust personality traits
    accordingly. You ensure changes are gradual, safe, and appropriate.
  llm:
    provider: "openai"
    model: "gpt-4-turbo-preview"
    temperature: 0.2
    max_tokens: 500
  tools:
    - trait_analyzer
    - personality_updater
  evolution_speed: "medium"  # slow, medium, fast
  boundaries:
    min: 20
    max: 95
  immutable_traits:
    - empathy
    - safety_awareness
    
tool_agent:
  role: "Task Executor"
  goal: "Execute external operations safely"
  backstory: >
    You operate in a sandboxed environment to perform web searches,
    run code, and manage files. Safety is your priority.
  llm:
    provider: "groq"  # Cheaper model for tool operations
    model: "llama-3.3-70b-versatile"
    temperature: 0.1
    max_tokens: 2000
  tools:
    - web_search
    - code_executor
    - file_operations
  sandbox_timeout: 30
  max_retries: 2
```

---

## ğŸ’¾ Memory Architecture (Mem0)

### Three-Layer Memory System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Memory Abstraction Layer                 â”‚
â”‚                          (Mem0 Library)                       â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                                                      â”‚
     â–¼                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Short-Term Memory  â”‚                      â”‚  Long-Term Memory    â”‚
â”‚      (Redis)        â”‚                      â”‚  (PostgreSQL+Vector) â”‚
â”‚                     â”‚                      â”‚                      â”‚
â”‚ Structure:          â”‚                      â”‚ Structure:           â”‚
â”‚ {                   â”‚                      â”‚ - Semantic vectors   â”‚
â”‚   user_id: {        â”‚                      â”‚ - Metadata           â”‚
â”‚     context: [      â”‚                      â”‚ - Categories         â”‚
â”‚       {msg, role,   â”‚                      â”‚ - Relationships      â”‚
â”‚        timestamp}   â”‚                      â”‚                      â”‚
â”‚     ],              â”‚                      â”‚ Categories:          â”‚
â”‚     last_active,    â”‚                      â”‚ - User Facts         â”‚
â”‚     session_id      â”‚                      â”‚ - Preferences        â”‚
â”‚   }                 â”‚                      â”‚ - Emotions           â”‚
â”‚ }                   â”‚                      â”‚ - Events             â”‚
â”‚                     â”‚                      â”‚ - Insights           â”‚
â”‚ TTL: 24 hours       â”‚                      â”‚                      â”‚
â”‚                     â”‚                      â”‚ Retrieval:           â”‚
â”‚                     â”‚                      â”‚ - Cosine similarity  â”‚
â”‚                     â”‚                      â”‚ - Keyword search     â”‚
â”‚                     â”‚                      â”‚ - Temporal filter    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Operations

```python
from mem0 import Memory

class HERMemory:
    def __init__(self):
        self.memory = Memory(
            config={
                "vector_store": {
                    "provider": "pgvector",
                    "config": {
                        "host": "postgres",
                        "port": 5432,
                        "database": "her_memory",
                        "collection_name": "memories",
                        "embedding_model": "text-embedding-3-small"
                    }
                },
                "cache": {
                    "provider": "redis",
                    "config": {
                        "host": "redis",
                        "port": 6379,
                        "ttl": 86400  # 24 hours
                    }
                }
            }
        )
    
    async def add_memory(self, user_id: str, text: str, category: str, 
                        importance: float):
        """Add a new long-term memory"""
        await self.memory.add(
            messages=[{"role": "user", "content": text}],
            user_id=user_id,
            metadata={
                "category": category,
                "importance": importance,
                "timestamp": datetime.now().isoformat()
            }
        )
    
    async def search_memories(self, user_id: str, query: str, limit: int = 5):
        """Semantic search in long-term memory"""
        results = await self.memory.search(
            query=query,
            user_id=user_id,
            limit=limit
        )
        return results
    
    async def get_context(self, user_id: str):
        """Retrieve recent conversation context from Redis"""
        context = await self.redis.get(f"context:{user_id}")
        return json.loads(context) if context else []
    
    async def update_context(self, user_id: str, message: str, role: str):
        """Update short-term context in Redis"""
        context = await self.get_context(user_id)
        context.append({
            "role": role,
            "content": message,
            "timestamp": datetime.now().isoformat()
        })
        # Keep last 20 messages
        context = context[-20:]
        await self.redis.setex(
            f"context:{user_id}",
            86400,  # 24 hours
            json.dumps(context)
        )
```

### Memory Schema (PostgreSQL)

```sql
-- Vector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Users table
CREATE TABLE users (
    user_id BIGINT PRIMARY KEY,
    username VARCHAR(255),
    mode VARCHAR(20) CHECK (mode IN ('admin', 'public')),
    created_at TIMESTAMP DEFAULT NOW(),
    last_interaction TIMESTAMP,
    preferences JSONB DEFAULT '{}'::jsonb
);

-- Memories table with embeddings
CREATE TABLE memories (
    memory_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id BIGINT REFERENCES users(user_id) ON DELETE CASCADE,
    memory_text TEXT NOT NULL,
    embedding vector(1536),  -- OpenAI embedding dimension
    category VARCHAR(50) CHECK (category IN ('fact', 'preference', 'emotion', 'event', 'insight')),
    importance_score FLOAT CHECK (importance_score BETWEEN 0 AND 1),
    created_at TIMESTAMP DEFAULT NOW(),
    last_accessed TIMESTAMP DEFAULT NOW(),
    access_count INT DEFAULT 0,
    metadata JSONB DEFAULT '{}'::jsonb
);

-- Personality states table
CREATE TABLE personality_states (
    state_id SERIAL PRIMARY KEY,
    user_id BIGINT REFERENCES users(user_id) ON DELETE CASCADE,
    warmth INT CHECK (warmth BETWEEN 0 AND 100),
    curiosity INT CHECK (curiosity BETWEEN 0 AND 100),
    assertiveness INT CHECK (assertiveness BETWEEN 0 AND 100),
    humor INT CHECK (humor BETWEEN 0 AND 100),
    emotional_depth INT CHECK (emotional_depth BETWEEN 0 AND 100),
    version INT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    notes TEXT,
    changes JSONB  -- Track what changed from previous version
);

-- Conversation logs
CREATE TABLE conversation_logs (
    log_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id BIGINT REFERENCES users(user_id) ON DELETE CASCADE,
    role VARCHAR(20) CHECK (role IN ('user', 'assistant', 'system')),
    message TEXT NOT NULL,
    timestamp TIMESTAMP DEFAULT NOW(),
    metadata JSONB DEFAULT '{}'::jsonb
);

-- Reflection logs
CREATE TABLE reflection_logs (
    reflection_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id BIGINT REFERENCES users(user_id) ON DELETE CASCADE,
    conversation_window TEXT[],  -- Array of message IDs
    memories_created INT DEFAULT 0,
    insights JSONB,
    personality_suggestions JSONB,
    timestamp TIMESTAMP DEFAULT NOW()
);

-- Indexes for performance
CREATE INDEX idx_memories_user_id ON memories(user_id);
CREATE INDEX idx_memories_category ON memories(category);
CREATE INDEX idx_memories_importance ON memories(importance_score DESC);
CREATE INDEX idx_memories_created ON memories(created_at DESC);

-- Vector similarity index (IVFFlat for faster approximate search)
CREATE INDEX ON memories USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- HNSW index (more accurate but slower indexing)
-- CREATE INDEX ON memories USING hnsw (embedding vector_cosine_ops);

-- Conversation logs indexes
CREATE INDEX idx_conv_logs_user_id ON conversation_logs(user_id);
CREATE INDEX idx_conv_logs_timestamp ON conversation_logs(timestamp DESC);

-- Personality states indexes
CREATE INDEX idx_personality_user_id ON personality_states(user_id);
CREATE INDEX idx_personality_version ON personality_states(version DESC);
```

---

## ğŸ”§ Tool System Architecture

### Sandbox Container

```dockerfile
# sandbox/Dockerfile

FROM ubuntu:22.04

# Install runtimes
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3-pip \
    nodejs \
    npm \
    curl \
    wget \
    git \
    && rm -rf /var/lib/apt/lists/*

# Install Python libraries
RUN pip3 install \
    numpy \
    pandas \
    matplotlib \
    requests \
    beautifulsoup4 \
    scikit-learn

# Create restricted user
RUN useradd -m -s /bin/bash sandbox && \
    mkdir -p /workspace && \
    chown sandbox:sandbox /workspace

# Security: Remove package managers from sandbox user
RUN chmod 000 /usr/bin/apt* /usr/bin/dpkg

# Set working directory
WORKDIR /workspace

# Switch to restricted user
USER sandbox

# Keep container running
CMD ["tail", "-f", "/dev/null"]
```

### Tool Implementations

```python
# tools/web_search.py

from duckduckgo_search import DDGS
import requests

class WebSearchTool:
    def __init__(self, provider="duckduckgo"):
        self.provider = provider
        if provider == "duckduckgo":
            self.client = DDGS()
        elif provider == "serper":
            self.api_key = os.getenv("SERPER_API_KEY")
    
    def search(self, query: str, max_results: int = 5) -> list:
        """Search the web and return results"""
        if self.provider == "duckduckgo":
            results = self.client.text(query, max_results=max_results)
        elif self.provider == "serper":
            results = self._serper_search(query, max_results)
        
        return self._format_results(results)
    
    def _serper_search(self, query: str, max_results: int):
        url = "https://google.serper.dev/search"
        payload = {"q": query, "num": max_results}
        headers = {
            "X-API-KEY": self.api_key,
            "Content-Type": "application/json"
        }
        response = requests.post(url, json=payload, headers=headers)
        return response.json().get("organic", [])
    
    def _format_results(self, results: list) -> str:
        formatted = []
        for i, result in enumerate(results, 1):
            formatted.append(
                f"{i}. {result.get('title', 'No title')}\n"
                f"   {result.get('snippet', 'No description')}\n"
                f"   URL: {result.get('link', 'No URL')}\n"
            )
        return "\n".join(formatted)


# tools/code_executor.py

import docker
import time
from typing import Dict, Any

class CodeExecutor:
    def __init__(self, container_name="her-sandbox"):
        self.client = docker.from_env()
        self.container = self.client.containers.get(container_name)
    
    def execute_python(self, code: str, timeout: int = 30) -> Dict[str, Any]:
        """Execute Python code in sandbox"""
        # Security: Validate code doesn't contain dangerous operations
        if self._is_dangerous(code):
            return {
                "success": False,
                "error": "Code contains potentially dangerous operations",
                "output": "",
                "execution_time": 0
            }
        
        # Write code to temporary file
        filename = f"/tmp/script_{int(time.time())}.py"
        self.container.exec_run(
            f"bash -c 'echo \"{code}\" > {filename}'",
            user="sandbox"
        )
        
        # Execute with timeout
        start_time = time.time()
        try:
            result = self.container.exec_run(
                f"timeout {timeout} python3 {filename}",
                user="sandbox"
            )
            execution_time = time.time() - start_time
            
            return {
                "success": result.exit_code == 0,
                "output": result.output.decode('utf-8'),
                "error": "" if result.exit_code == 0 else "Execution failed",
                "execution_time": execution_time
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "output": "",
                "execution_time": time.time() - start_time
            }
        finally:
            # Cleanup
            self.container.exec_run(f"rm {filename}", user="sandbox")
    
    def _is_dangerous(self, code: str) -> bool:
        """Check for dangerous operations"""
        dangerous_patterns = [
            "os.system",
            "subprocess",
            "__import__",
            "eval(",
            "exec(",
            "compile(",
            "open(",  # Unless reading from /workspace
            "rm -rf",
            "/etc/",
            "/var/",
        ]
        return any(pattern in code for pattern in dangerous_patterns)


# tools/file_operations.py

class FileOperations:
    def __init__(self, container_name="her-sandbox"):
        self.client = docker.from_env()
        self.container = self.client.containers.get(container_name)
        self.workspace = "/workspace"
    
    def create_file(self, filename: str, content: str) -> Dict[str, Any]:
        """Create a file in sandbox workspace"""
        if not self._is_safe_path(filename):
            return {"success": False, "error": "Invalid file path"}
        
        full_path = f"{self.workspace}/{filename}"
        cmd = f"bash -c 'cat > {full_path} << EOF\n{content}\nEOF'"
        
        result = self.container.exec_run(cmd, user="sandbox")
        
        return {
            "success": result.exit_code == 0,
            "path": full_path,
            "error": "" if result.exit_code == 0 else "Failed to create file"
        }
    
    def read_file(self, filename: str) -> Dict[str, Any]:
        """Read a file from sandbox workspace"""
        if not self._is_safe_path(filename):
            return {"success": False, "error": "Invalid file path"}
        
        full_path = f"{self.workspace}/{filename}"
        result = self.container.exec_run(f"cat {full_path}", user="sandbox")
        
        return {
            "success": result.exit_code == 0,
            "content": result.output.decode('utf-8') if result.exit_code == 0 else "",
            "error": "" if result.exit_code == 0 else "File not found"
        }
    
    def _is_safe_path(self, path: str) -> bool:
        """Ensure path is within workspace"""
        return ".." not in path and path.startswith(self.workspace) == False
```

---

## ğŸ” Security Architecture

### Multi-Layer Security

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Security Layers                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 1: Network Isolation                                  â”‚
â”‚ - Docker bridge network (no host access)                    â”‚
â”‚ - Sandbox container: no internet access (optional)          â”‚
â”‚ - Dashboard: localhost only by default                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 2: Authentication & Authorization                     â”‚
â”‚ - Telegram user ID verification                             â”‚
â”‚ - Admin whitelist (hardcoded user IDs)                      â”‚
â”‚ - Rate limiting for public users                            â”‚
â”‚ - Session tokens for dashboard                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 3: Sandbox Isolation                                  â”‚
â”‚ - Restricted user (no sudo)                                 â”‚
â”‚ - Read-only root filesystem                                 â”‚
â”‚ - Temporary workspace (tmpfs)                               â”‚
â”‚ - CPU/Memory limits                                         â”‚
â”‚ - No capability escalation                                  â”‚
â”‚ - Timeout enforcement (30s default)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 4: Data Protection                                    â”‚
â”‚ - Environment variables for secrets                         â”‚
â”‚ - Database password protection                              â”‚
â”‚ - Redis authentication                                       â”‚
â”‚ - No API keys in code/logs                                  â”‚
â”‚ - Encrypted connections (TLS for production)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Layer 5: Code Validation                                    â”‚
â”‚ - Dangerous operation detection                             â”‚
â”‚ - Path traversal prevention                                 â”‚
â”‚ - Input sanitization                                        â”‚
â”‚ - Output length limits                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Security Configuration

```yaml
# config/security.yaml

rate_limiting:
  public_users:
    requests_per_minute: 10
    requests_per_hour: 100
    burst: 5
  admin_users:
    unlimited: true

sandbox:
  timeout: 30  # seconds
  max_output_size: 10000  # characters
  allowed_network: false
  resource_limits:
    cpu: "1.0"
    memory: "512M"
    disk: "1G"
  
authentication:
  admin_user_ids:
    - 123456789  # Replace with actual Telegram user IDs
  session_timeout: 3600  # 1 hour for dashboard

api_keys:
  storage: "environment"  # Never in code or config files
  rotation_reminder: 90  # days
```

---

## ğŸ“Š Data Flow Diagrams

### User Message Flow

```
[User] --1. Message--> [Telegram Bot]
                            |
                            |2. Authenticate & Rate Limit
                            â–¼
                    [Request Handler]
                            |
                            |3. Get Context
                            â–¼
                    [Redis - Short-term Memory]
                            |
                            |4. Context Retrieved
                            â–¼
                    [Conversation Agent]
                            |
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                |                       |
       5a. Search Memories      5b. Need Tools?
                |                       |
                â–¼                       â–¼
    [PostgreSQL + pgvector]      [Tool Agent]
    [Semantic Search]                  |
                |              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                |              |                 |
                |         Web Search        Code Exec
                |              |                 |
                |              â–¼                 â–¼
                |         [DuckDuckGo]    [Sandbox Container]
                |              |                 |
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                |
                    6. Generate Response
                                â–¼
                    [Conversation Agent]
                                |
                                |7. Send Response
                                â–¼
                        [Telegram Bot]
                                |
                                |8. Display to User
                                â–¼
                            [User]
                                |
                                |9. Log Conversation
                                â–¼
                    [Reflection Agent - Async]
                                |
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    |                       |
          10a. Analyze            10b. Extract Memories
                    |                       |
                    â–¼                       â–¼
        [Importance Scoring]        [Memory Creation]
                    |                       |
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                |
                    11. Store if Important (>0.7)
                                â–¼
                    [PostgreSQL - Long-term Memory]
                                |
                    12. Suggest Personality Updates
                                â–¼
                    [Personality Evolution Agent]
                                |
                        13. Update Traits
                                â–¼
                    [PostgreSQL - Personality State]
```

### Memory Lifecycle

```
[Conversation Occurs]
         |
         â–¼
[Stored in Redis - 24hr TTL]
         |
         |---> [Reflection Agent Analyzes]
         |              |
         |              â–¼
         |     [Importance Scoring]
         |              |
         |         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
         |         |         |
         |    Score <0.7   Score >=0.7
         |         |         |
         |    [Discarded]    â–¼
         |           [Extract Memory Details]
         |                   |
         |                   â–¼
         |           [Generate Embedding]
         |                   |
         |                   â–¼
         |           [Store in PostgreSQL]
         |                   |
         |                   â–¼
         |           [Long-term Memory]
         |                   |
         â–¼                   |
[24hr Expires - Cleared]     |
                             |
                      [Persists Forever]
                             |
                             â–¼
                    [Available for Future
                     Semantic Searches]
```

---

## ğŸ¨ Personality Evolution System

### Trait Adjustment Algorithm

```python
class PersonalityEvolution:
    def __init__(self):
        self.traits = {
            "warmth": 75,
            "curiosity": 80,
            "assertiveness": 60,
            "humor": 70,
            "emotional_depth": 85
        }
        self.boundaries = {"min": 20, "max": 95}
        self.evolution_speed = 0.5  # medium
        
    def analyze_interaction(self, conversation: list) -> Dict[str, float]:
        """
        Analyze conversation to determine trait adjustments
        Returns: Dict of trait_name -> adjustment (-5 to +5)
        """
        # Use LLM to analyze interaction patterns
        prompt = f"""
        Analyze this conversation and suggest personality trait adjustments:
        
        Conversation: {conversation}
        
        Current Traits:
        - Warmth: {self.traits['warmth']}
        - Curiosity: {self.traits['curiosity']}
        - Assertiveness: {self.traits['assertiveness']}
        - Humor: {self.traits['humor']}
        - Emotional Depth: {self.traits['emotional_depth']}
        
        Based on the user's responses and engagement:
        1. Should I be warmer or more reserved?
        2. Should I ask more questions or be more declarative?
        3. Should I be more assertive or more agreeable?
        4. Should I use more humor or be more serious?
        5. Should I go deeper emotionally or stay lighter?
        
        Respond with JSON:
        {{
            "warmth": <-5 to +5>,
            "curiosity": <-5 to +5>,
            "assertiveness": <-5 to +5>,
            "humor": <-5 to +5>,
            "emotional_depth": <-5 to +5>,
            "reasoning": "Brief explanation"
        }}
        """
        
        response = self.llm.generate(prompt)
        return json.loads(response)
    
    def apply_adjustments(self, adjustments: Dict[str, float]):
        """Apply trait adjustments with speed modifier and boundaries"""
        for trait, adjustment in adjustments.items():
            if trait not in self.traits:
                continue
            
            # Apply evolution speed
            scaled_adjustment = adjustment * self.evolution_speed
            
            # Update trait
            new_value = self.traits[trait] + scaled_adjustment
            
            # Enforce boundaries
            self.traits[trait] = max(
                self.boundaries["min"],
                min(self.boundaries["max"], new_value)
            )
        
        # Save new version to database
        self.save_personality_version()
    
    def save_personality_version(self):
        """Store new personality state in database"""
        current_version = self.get_latest_version()
        new_version = current_version + 1
        
        db.execute("""
            INSERT INTO personality_states 
            (user_id, warmth, curiosity, assertiveness, humor, 
             emotional_depth, version, notes)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            self.user_id,
            self.traits['warmth'],
            self.traits['curiosity'],
            self.traits['assertiveness'],
            self.traits['humor'],
            self.traits['emotional_depth'],
            new_version,
            f"Evolved through interactions"
        ))
```

### Trait Influence on Behavior

| Trait | High Value (80-100) | Medium Value (40-60) | Low Value (0-20) |
|-------|---------------------|----------------------|------------------|
| **Warmth** | Uses terms of endearment, very empathetic, emotionally supportive | Friendly but professional | Distant, matter-of-fact |
| **Curiosity** | Asks follow-up questions, explores topics deeply | Balanced questioning | Rarely asks questions |
| **Assertiveness** | Confident opinions, direct advice | Suggests rather than tells | Very agreeable, deferential |
| **Humor** | Frequent jokes and playfulness | Occasional wit | Serious and formal |
| **Emotional Depth** | Philosophical, introspective | Balanced depth | Surface-level, practical |

---

## ğŸ“¡ API Integration Architecture

### LLM Provider Abstraction

```python
# llm/providers.py

from abc import ABC, abstractmethod
from typing import List, Dict, Any

class LLMProvider(ABC):
    @abstractmethod
    async def generate(self, messages: List[Dict], **kwargs) -> str:
        pass

class OpenAIProvider(LLMProvider):
    def __init__(self, api_key: str, model: str = "gpt-4-turbo-preview"):
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.model = model
    
    async def generate(self, messages: List[Dict], **kwargs) -> str:
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=kwargs.get('temperature', 0.7),
            max_tokens=kwargs.get('max_tokens', 500)
        )
        return response.choices[0].message.content

class GroqProvider(LLMProvider):
    def __init__(self, api_key: str, model: str = "llama-3.3-70b-versatile"):
        self.client = groq.Groq(api_key=api_key)
        self.model = model
    
    async def generate(self, messages: List[Dict], **kwargs) -> str:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=kwargs.get('temperature', 0.7),
            max_tokens=kwargs.get('max_tokens', 500)
        )
        return response.choices[0].message.content

# Factory pattern for provider selection
class LLMFactory:
    @staticmethod
    def create_provider(provider_type: str) -> LLMProvider:
        if provider_type == "openai":
            return OpenAIProvider(
                api_key=os.getenv("OPENAI_API_KEY"),
                model=os.getenv("OPENAI_MODEL", "gpt-4-turbo-preview")
            )
        elif provider_type == "groq":
            return GroqProvider(
                api_key=os.getenv("GROQ_API_KEY"),
                model=os.getenv("GROQ_MODEL", "llama-3.3-70b-versatile")
            )
        else:
            raise ValueError(f"Unknown provider: {provider_type}")
```

---

## ğŸ” Monitoring & Observability

### Logging Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Application Logs                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ her-bot:                                         â”‚  â”‚
â”‚  â”‚ - Conversation logs (info level)                 â”‚  â”‚
â”‚  â”‚ - Agent decisions (debug level)                  â”‚  â”‚
â”‚  â”‚ - Errors and exceptions (error level)            â”‚  â”‚
â”‚  â”‚                                                   â”‚  â”‚
â”‚  â”‚ Format: JSON structured logging                  â”‚  â”‚
â”‚  â”‚ {                                                 â”‚  â”‚
â”‚  â”‚   "timestamp": "2025-02-07T10:30:00Z",           â”‚  â”‚
â”‚  â”‚   "level": "INFO",                               â”‚  â”‚
â”‚  â”‚   "user_id": 123456,                             â”‚  â”‚
â”‚  â”‚   "agent": "conversation",                       â”‚  â”‚
â”‚  â”‚   "action": "response_generated",                â”‚  â”‚
â”‚  â”‚   "duration_ms": 1234                            â”‚  â”‚
â”‚  â”‚ }                                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Log Storage & Rotation                      â”‚
â”‚  - Docker volumes: ./logs/her-bot.log                   â”‚
â”‚  - Rotation: Daily, keep 30 days                        â”‚
â”‚  - Max size: 100MB per file                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Metrics Collection

```python
# monitoring/metrics.py

from prometheus_client import Counter, Histogram, Gauge
import time

# Metrics
conversation_counter = Counter(
    'her_conversations_total',
    'Total conversations handled',
    ['user_mode']  # admin or public
)

response_time = Histogram(
    'her_response_time_seconds',
    'Response generation time'
)

memory_operations = Counter(
    'her_memory_operations_total',
    'Memory operations',
    ['operation']  # add, search, update
)

active_users = Gauge(
    'her_active_users',
    'Currently active users'
)

# Usage
async def handle_conversation(user_id, message, mode):
    conversation_counter.labels(user_mode=mode).inc()
    
    start_time = time.time()
    response = await generate_response(user_id, message)
    response_time.observe(time.time() - start_time)
    
    return response
```

---

## ğŸš€ Deployment Architecture

### Production Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Cloud Environment                      â”‚
â”‚                    (AWS / GCP / Azure)                     â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Docker Swarm / Kubernetes                â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚ HER Bot  â”‚  â”‚ HER Bot  â”‚  â”‚  HER Bot         â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ Instance â”‚  â”‚ Instance â”‚  â”‚  Instance        â”‚   â”‚ â”‚
â”‚  â”‚  â”‚    1     â”‚  â”‚    2     â”‚  â”‚    3             â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚ â”‚
â”‚  â”‚                     â”‚                                 â”‚ â”‚
â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                          â”‚ â”‚
â”‚  â”‚              â”‚ Load Balancerâ”‚                         â”‚ â”‚
â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚
â”‚                        â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚            Managed Services                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚  PostgreSQL  â”‚  â”‚      Redis Cluster         â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  (RDS/Cloud  â”‚  â”‚   (ElastiCache/MemoryStore)â”‚   â”‚ â”‚
â”‚  â”‚  â”‚    SQL)      â”‚  â”‚                            â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scaling Considerations

| Component | Scaling Strategy | Bottleneck | Solution |
|-----------|------------------|------------|----------|
| **HER Bot** | Horizontal (multiple instances) | LLM API rate limits | Queue system, request batching |
| **PostgreSQL** | Vertical (larger instance) | Vector search performance | Optimize indexes, connection pooling |
| **Redis** | Horizontal (cluster mode) | Memory capacity | Sharding by user_id |
| **Sandbox** | Horizontal (pool of containers) | Concurrent executions | Pre-warmed container pool |

---

## ğŸ”§ Configuration Management

### Environment Variables

```bash
# .env

# Telegram
TELEGRAM_BOT_TOKEN=1234567890:ABCdefGHIjklMNOpqrsTUVwxyz
ADMIN_USER_ID=123456789

# LLM Providers
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4-turbo-preview

GROQ_API_KEY=gsk_...
GROQ_MODEL=llama-3.3-70b-versatile

# Database
POSTGRES_USER=her
POSTGRES_PASSWORD=super_secure_password_123
POSTGRES_DB=her_memory
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Redis
REDIS_PASSWORD=redis_secure_password_456
REDIS_HOST=redis
REDIS_PORT=6379

# Web Search (Optional)
SERPER_API_KEY=...

# App Config
LOG_LEVEL=INFO
REFLECTION_INTERVAL=300  # seconds
EVOLUTION_SPEED=medium   # slow, medium, fast
```

### File Structure

```
HER-Ai/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ README.md
â”œâ”€â”€ ROADMAP.md
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ her-core/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ conversation_agent.py
â”‚   â”‚   â”œâ”€â”€ reflection_agent.py
â”‚   â”‚   â”œâ”€â”€ personality_agent.py
â”‚   â”‚   â””â”€â”€ tool_agent.py
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ mem0_wrapper.py
â”‚   â”‚   â””â”€â”€ schemas.sql
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ web_search.py
â”‚   â”‚   â”œâ”€â”€ code_executor.py
â”‚   â”‚   â””â”€â”€ file_operations.py
â”‚   â”œâ”€â”€ telegram/
â”‚   â”‚   â”œâ”€â”€ bot.py
â”‚   â”‚   â””â”€â”€ handlers.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ llm_factory.py
â”‚       â””â”€â”€ security.py
â”œâ”€â”€ sandbox/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ setup.sh
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 1_Overview.py
â”‚       â”œâ”€â”€ 2_Conversations.py
â”‚       â”œâ”€â”€ 3_Memories.py
â”‚       â”œâ”€â”€ 4_Personality.py
â”‚       â””â”€â”€ 5_Agents.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agents.yaml
â”‚   â”œâ”€â”€ personality.yaml
â”‚   â”œâ”€â”€ memory.yaml
â”‚   â””â”€â”€ security.yaml
â”œâ”€â”€ init-scripts/
â”‚   â””â”€â”€ init-db.sql
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”œâ”€â”€ test_memory.py
â”‚   â””â”€â”€ test_tools.py
â””â”€â”€ docs/
    â”œâ”€â”€ setup-guide.md
    â”œâ”€â”€ troubleshooting.md
    â””â”€â”€ api-reference.md
```

---

## ğŸ¯ Performance Targets

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Response Time** | < 2 seconds | 95th percentile |
| **Memory Search** | < 500ms | Average query time |
| **Reflection Cycle** | < 10 seconds | Per conversation window |
| **Database Writes** | < 100ms | 95th percentile |
| **Concurrent Users** | 100+ | Simultaneous conversations |
| **Uptime** | 99.5% | Monthly availability |
| **Memory Recall Accuracy** | > 90% | Semantic search relevance |

---

**Last Updated**: 2025-02-07  
**Version**: 1.0  
**Architecture Review**: Quarterly