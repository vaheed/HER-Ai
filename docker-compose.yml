services:
  her-bot:
    image: ghcr.io/vaheed/her-ai/her-bot:latest
    build:
      context: .
      dockerfile: her-core/Dockerfile
    container_name: her-bot
    env_file:
    - .env
    ports:
    - 8000:8000
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
      ollama-init:
        condition: service_completed_successfully
    networks:
    - her-network
    restart: unless-stopped
    user: "0:0"
    healthcheck:
      test:
      - CMD
      - python
      - -c
      - import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost',
        8000)); s.close()
      interval: 30s
      timeout: 5s
      retries: 3
    environment:
    - TELEGRAM_BOT_TOKEN
    - ADMIN_USER_ID
    - LLM_PROVIDER
    - OPENAI_API_KEY
    - GROQ_API_KEY
    - POSTGRES_URL
    - REDIS_HOST
    - REDIS_PASSWORD
    - BRAVE_API_KEY
    - MCP_CONFIG_PATH
    - SANDBOX_CONTAINER_NAME
    - HER_CONFIG_DIR
    - DOCKER_GID
    - TZ
    volumes:
    - her_config:/app/config
    - ./logs:/app/logs
    - /var/run/docker.sock:/var/run/docker.sock
    - workspace:/workspace
  postgres:
    image: pgvector/pgvector:pg17
    container_name: her-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-her}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme123}
      POSTGRES_DB: ${POSTGRES_DB:-her_memory}
      TZ: ${TZ:-UTC}
    volumes:
    - postgres_data:/var/lib/postgresql/data
    networks:
    - her-network
    restart: unless-stopped
    healthcheck:
      test:
      - CMD-SHELL
      - pg_isready -U ${POSTGRES_USER:-her} -d ${POSTGRES_DB:-her_memory}
      interval: 10s
      timeout: 5s
      retries: 5
  redis:
    image: redis:7.4-alpine
    container_name: her-redis
    command:
    - redis-server
    - --appendonly
    - 'yes'
    - --requirepass
    - ${REDIS_PASSWORD:-changeme456}
    volumes:
    - redis_data:/data
    ports:
    - 6379:6379
    environment:
      TZ: ${TZ:-UTC}
    networks:
    - her-network
    restart: unless-stopped
    healthcheck:
      test:
      - CMD
      - redis-cli
      - -a
      - ${REDIS_PASSWORD:-changeme456}
      - ping
      interval: 10s
      timeout: 5s
      retries: 5
  ollama:
    image: ollama/ollama:latest
    container_name: her-ollama
    volumes:
    - ollama_data:/root/.ollama
    ports:
    - 11434:11434
    environment:
      TZ: ${TZ:-UTC}
    networks:
    - her-network
    restart: unless-stopped
    mem_limit: 2g
    cpus: 1.5
    healthcheck:
      test:
      - CMD
      - bash
      - -lc
      - OLLAMA_HOST=http://localhost:11434 ollama list >/dev/null 2>&1
      interval: 30s
      timeout: 5s
      retries: 10
  ollama-init:
    image: ollama/ollama:latest
    container_name: her-ollama-init
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_HOST: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:3b}
      OLLAMA_EMBED_MODEL: ${OLLAMA_EMBED_MODEL:-nomic-embed-text}
      TZ: ${TZ:-UTC}
    entrypoint:
    - /bin/bash
    - -lc
    command: '''set -e; echo "Waiting for Ollama at $OLLAMA_BASE_URL"; until OLLAMA_HOST="$OLLAMA_HOST"
      ollama list >/dev/null 2>&1; do sleep 2; done; echo "Pulling embedding model:
      $OLLAMA_EMBED_MODEL"; OLLAMA_HOST="$OLLAMA_HOST" ollama pull "$OLLAMA_EMBED_MODEL";
      echo "Pulling chat model: $OLLAMA_MODEL"; OLLAMA_HOST="$OLLAMA_HOST" ollama
      pull "$OLLAMA_MODEL"; echo "Ollama models ready."''

      '
    networks:
    - her-network
    restart: 'no'
  sandbox:
    image: ghcr.io/vaheed/her-ai/her-sandbox:latest
    build:
      context: .
      dockerfile: sandbox/Dockerfile
    container_name: her-sandbox
    networks:
    - her-network
    restart: unless-stopped
    environment:
      TZ: ${TZ:-UTC}
    read_only: true
    tmpfs:
    - /tmp:noexec,nosuid,size=100m
    volumes:
    - sandbox_workspace:/workspace
    healthcheck:
      test:
      - CMD
      - bash
      - -lc
      - test -d /workspace
      interval: 30s
      timeout: 5s
      retries: 3
  dashboard:
    image: ghcr.io/vaheed/her-ai/her-dashboard:latest
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    container_name: her-dashboard
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
      ollama-init:
        condition: service_completed_successfully
    env_file:
    - .env
    ports:
    - 8501:8501
    environment:
      TZ: ${TZ:-UTC}
    networks:
    - her-network
    restart: unless-stopped
    healthcheck:
      test:
      - CMD
      - python
      - -c
      - import socket; s=socket.socket(); s.settimeout(2); s.connect(('localhost',
        8501)); s.close()
      interval: 30s
      timeout: 5s
      retries: 3
networks:
  her-network:
    driver: bridge
volumes:
  postgres_data: null
  redis_data: null
  sandbox_workspace: null
  ollama_data: null
  workspace: null
  her_config: null
