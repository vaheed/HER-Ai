# HER-Ai environment template
#
# Best practices:
# - Copy this file to `.env` and fill real secrets there.
# - Never commit real API keys/tokens/passwords.
# - Use strong random passwords in production.
# - Keep `TZ=UTC` unless you have a strict local-time requirement.
# - Prefer least-privilege access for all external services.

# ============================================================
# Runtime / App
# ============================================================
# Log verbosity: DEBUG | INFO | WARNING | ERROR
LOG_LEVEL=INFO
# Environment label used by runtime diagnostics.
ENVIRONMENT=development
# Keep UTC for deterministic system scheduling/logging.
TZ=UTC
# Default timezone for users when no explicit per-user timezone exists.
USER_TIMEZONE=UTC

# Optional startup compatibility check.
# Keep disabled by default to avoid noisy failures during boot when providers are unavailable.
STARTUP_WARMUP_ENABLED=false

# ============================================================
# Workflow Debug Visualization
# ============================================================
# Realtime workflow graph + timeline server.
WORKFLOW_DEBUG_SERVER_ENABLED=true
WORKFLOW_DEBUG_HOST=0.0.0.0
WORKFLOW_DEBUG_PORT=8081

# OpenAPI adapter for Slack/custom clients (works without Telegram).
API_ADAPTER_ENABLED=true
API_ADAPTER_HOST=0.0.0.0
API_ADAPTER_PORT=8082
# Optional bearer token for OpenAI-compatible clients.
# If set, send as Authorization: Bearer <token>.
API_ADAPTER_BEARER_TOKEN=
# Model name advertised by /v1/models and accepted by /v1/chat/completions.
API_ADAPTER_MODEL_NAME=her-chat-1


# ============================================================
# LLM Routing
# ============================================================
# Primary chat provider: ollama | openai | groq | openrouter
# Local-first recommendation for development: ollama
LLM_PROVIDER=ollama

# Enable failover when primary returns transient upstream errors (502/503).
LLM_ENABLE_FALLBACK=true
# Suggested fallback for local/dev reliability.
LLM_FALLBACK_PROVIDER=ollama


# ============================================================
# Ollama (local models)
# ============================================================
# Chat model used when LLM_PROVIDER=ollama.
OLLAMA_MODEL=llama3.2:3b
# Internal runtime URL used by her-core.
OLLAMA_BASE_URL=http://ollama:11434
# Optional compatibility host used by tooling/init flows.
OLLAMA_HOST=http://ollama:11434
# Embedding model pre-pull target for compose init jobs.
OLLAMA_EMBED_MODEL=nomic-embed-text


# ============================================================
# OpenAI (cloud provider; used only when selected)
# ============================================================
# Example format only. Replace with your real key in `.env`.
OPENAI_API_KEY=sk-...
# Cost/perf balanced default.
OPENAI_MODEL=gpt-4o-mini


# ============================================================
# Groq (cloud provider; used only when selected)
# ============================================================
GROQ_API_KEY=gsk_...
GROQ_MODEL=llama-3.3-70b-versatile
GROQ_API_BASE=https://api.groq.com/openai/v1


# ============================================================
# OpenRouter (cloud provider; used only when selected)
# ============================================================
OPENROUTER_API_KEY=sk-or-...
OPENROUTER_MODEL=meta-llama/llama-3.3-70b-instruct
OPENROUTER_API_BASE=https://openrouter.ai/api/v1


# ============================================================
# Memory / Embeddings
# ============================================================
# Vector backend for long-term memory.
MEMORY_VECTOR_PROVIDER=pgvector
# Logical collection name in memory store.
MEMORY_COLLECTION_NAME=memories
# When false, bot keeps replying if memory backend is degraded.
# Recommended in production for graceful degradation.
MEMORY_STRICT_MODE=false

# Embedder provider: ollama | openai
EMBEDDER_PROVIDER=ollama
EMBEDDING_MODEL=nomic-embed-text
# Must match embedding model dimensions.
EMBEDDING_DIMENSIONS=768


# ============================================================
# PostgreSQL
# ============================================================
# Use non-default credentials in production.
POSTGRES_USER=her
POSTGRES_PASSWORD=changeme123
POSTGRES_DB=her_memory
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
# Connection URL used by some MCP/database tooling paths.
POSTGRES_URL=postgresql://her:changeme123@postgres:5432/her_memory


# ============================================================
# Redis
# ============================================================
REDIS_HOST=redis
REDIS_PORT=6379
# Use a strong secret in production.
REDIS_PASSWORD=changeme456


# ============================================================
# Telegram
# ============================================================
# Set false to run core services without Telegram polling.
TELEGRAM_ENABLED=true
# Bot token from BotFather.
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
# Retry delay (seconds) when Telegram API is temporarily unreachable.
TELEGRAM_STARTUP_RETRY_DELAY_SECONDS=10

# Admin controls
# Comma-safe source for admin access (single env entry expected by runtime).
# Use your numeric Telegram user ID.
ADMIN_USER_ID=your_telegram_user_id

# Public mode controls
TELEGRAM_PUBLIC_APPROVAL_REQUIRED=true
TELEGRAM_PUBLIC_RATE_LIMIT_PER_MINUTE=20


# ============================================================
# Intent / Action Execution Guards
# ============================================================
# Max autonomous operator steps (legacy/autonomous workflows).
HER_AUTONOMOUS_MAX_STEPS=16
# Default command timeout for sandbox execution paths.
HER_SANDBOX_COMMAND_TIMEOUT_SECONDS=60
# Confidence threshold before switching from CHAT_MODE to ACTION_MODE.
# Keep high to avoid accidental tool execution on conversational messages.
HER_ACTION_INTENT_THRESHOLD=0.8
# Per-command sandbox CPU/memory guardrails.
HER_SANDBOX_CPU_TIME_LIMIT_SECONDS=20
HER_SANDBOX_MEMORY_LIMIT_MB=512
# Enable proactive outbound follow-up/check-in messages from scheduler.
# Keep false for production-safe "no unsolicited follow-up" behavior.
HER_PROACTIVE_MESSAGES_ENABLED=false
# APScheduler persistent job store DSN (falls back to PostgreSQL env if unset).
SCHEDULER_DATABASE_URL=


# ============================================================
# MCP / Sandbox Runtime
# ============================================================
# MCP profile file under config directory.
MCP_CONFIG_PATH=mcp_servers.yaml
# Per-server MCP startup timeout in seconds.
# Runtime continues if some servers fail/time out.
MCP_SERVER_START_TIMEOUT_SECONDS=60

# Sandbox container target for all isolated command execution.
SANDBOX_CONTAINER_NAME=her-sandbox

# Optional config directory override inside container.
# Leave as `/app/config` for normal compose usage.
# If your runtime config is read-only, entrypoint may fallback to defaults.
HER_CONFIG_DIR=/app/config

# Optional: Docker group id when running her-bot non-root with docker socket access.
# Default compose usually does not require changing this.
DOCKER_GID=998


# ============================================================
# Optional third-party integrations
# ============================================================
# Optional Brave Search key (only needed if Brave-backed features are enabled).
BRAVE_API_KEY=your_brave_api_key_here
